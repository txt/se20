<a name=top><br>
<a href="http://tiny.cc/seng20"><img  width=700
  src="https://raw.githubusercontent.com/txt/se20/master/etc/img/teamBanner.png"></a>
<hr>
<p>
&nbsp;<a href="https://tiny.cc/seng20">home</a> ::
<a href="https://github.com/txt/se20/blob/master/docs/syllabus.md#top">syllabus</a> ::
<a href="https://github.com/txt/se20/blob/master/docs/syllabus.md#timetable">timetable</a> ::
<a href="https://drive.google.com/drive/folders/1ZFn6H8-4kx5uP34bpFgIFonkz9Tw3nYM?usp=sharing">groups</a> ::
<a href="https://moodle-courses2021.wolfware.ncsu.edu/course/view.php?id=3873">moodle</a> ::
<a href="http://seng20.slack.com">chat</a>  ::
<a href="https://github.com/txt/se20/blob/master/LICENSE.md#top">&copy; 2020</a>  
<br>
<hr>

# Review 4
## Define the following terms

- V-diagram, requirements and their connection to testing
- unit test, systems test, integration test, acceptance test (alpha, beta)
- state space (and make an argument that the state space inside software is very large).

## TDD

- Define what _is not_ TDD; specifically, describe the order in which tests are created in the _waterfall model_
- Define  test-driven-development (include the terms red, green refactor
- Hansson (2013) warns against driving the design from unit tests. Comment. Include in your answer terms like "greedy search". How might refactoring mitigate (to some extent) for Hansson's concerns?
- Karac + Turhan (2018) warn that early reports on the value of TDD might have accidentally conflated another effect. What was that effect? (hint: see first question in this list).

## Reasoning about Design

### Constraints

Consider the following feature map. 
- Suggest some _cross-tree Constraints_ (and maybe some more features) that might make this
product line more secure.
- Given those constraints, describe (a) two mutually exclusive products that make _different_ decisions about the cross-tree constraints; (b) explain why/why-not each product makes those different decisions

<img src="https://upload.wikimedia.org/wikipedia/commons/d/d6/E-shopFM.jpg">

### Goals

In  the Sayyad and Menzies [ICSE' 2013 experiment](https://fada.birzeit.edu/jspui/bitstream/20.500.11889/4528/1/dcb6eddbdac1c26b605ce3dff62e27167848.pdf), 
the software design was expressed as the process of pulling a "product" from a "product line".
To do that, that took BIG feature models (much bigger than the one shown above) and added in measurements to each feature for 
wwere feature was labelled with:

- BUGS: how many bugs were (previously) seen with this feature
- TIME: how long it took (previously) to create this feature
- FAMILIARITY: how often the current developers have used each feature
- PRECEDENCE: how often this feature appears in the other produced

Using that feature model and these labels:
- Describe how to find a "good" product (where "good" is uses the above measurements).
- Multi-objective measures of "goodness" often struggle with mutually-exclusive requirements. Can you think of any ways the above measures could interact, to confuse our definition of "good"?
- There are four measurements listed above. Can you think  of any other ways to measure product "good ness"?

For 1,000,000 points and a Ph.D. answer the following question:

- What is a genetic algorithm?
- Sayyad and Menzies explored the GAs listed in Table8 of that paper. Describe the essential difference between IBEA and the rest and why Sayyad and Menzies were do excited about that algorithm?
